{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f15020e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Trouver la racine du projet en remontant jusqu'à un dossier qui contient \"src\"\n",
    "cwd = Path().resolve()\n",
    "\n",
    "project_root = None\n",
    "for p in [cwd] + list(cwd.parents):\n",
    "    if (p / \"src\").exists():\n",
    "        project_root = p\n",
    "        break\n",
    "\n",
    "if project_root is None:\n",
    "    raise RuntimeError(f\"Impossible de trouver la racine du projet depuis: {cwd}\")\n",
    "\n",
    "sys.path.insert(0, str(project_root))\n",
    "project_root\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b40bd914",
   "metadata": {},
   "source": [
    "# 01 - Exploration du dataset\n",
    "\n",
    "Dataset: **Chest X-ray (pneumonia)**\n",
    "Objectif: Analyser la structure, la distribution et la qualité des données avant tout entrainement.\n",
    "\n",
    "Questions auxquelles ce notebook répond :\n",
    "1. Combien d'images par split (train/val/test) et par classe (NORMAL/PNEUMONIA) ?\n",
    "2. Le dataset est-il équilibré ?\n",
    "3. À quoi ressemble les images (qualité, contraste, exemples) ?\n",
    "4. Quelles contraintes techniques en découle pour le processing (tailles, canaux, valeurs, pixels) ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d377f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from collections import Counter\n",
    "from pathlib import Path\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "from src.config import CFG\n",
    "from src.data.load import index_chest_xray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a26584",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(CFG.SEED)\n",
    "np.random.seed(CFG.SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "400f1a3d",
   "metadata": {},
   "source": [
    "## 1) Chargement du dataset\n",
    "\n",
    "On indexe le dataset : pour chaque split, on récupère la liste des chemins d’images et leurs labels numériques (0 = normal, 1 = pneumonia).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e204cd0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = index_chest_xray()\n",
    "\n",
    "train_ds = splits[\"train\"]\n",
    "val_ds = splits[\"val\"]\n",
    "test_ds = splits[\"test\"]\n",
    "\n",
    "train_ds.class_to_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca37c7d",
   "metadata": {},
   "source": [
    "## 2) Volumes par split\n",
    "\n",
    "On commence par mesurer combien d’images sont disponibles dans chaque split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2391f529",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train:\", len(train_ds))\n",
    "print(\"Val  :\", len(val_ds))\n",
    "print(\"Test :\", len(test_ds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa64133",
   "metadata": {},
   "source": [
    "## 3) Distribution des classes\n",
    "\n",
    "On calcule combien d’images appartiennent à chaque classe, pour chaque split.\n",
    "Cela permet d’identifier un éventuel **déséquilibre** du dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ca7faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_distribution(ds) -> dict[str, int]:\n",
    "    counts = Counter(ds.labels)\n",
    "    idx_to_class = {v: k for k, v in ds.class_to_idx.items()}\n",
    "    return {idx_to_class[idx]: counts.get(idx, 0) for idx in idx_to_class}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c3231b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train:\", class_distribution(train_ds))\n",
    "print(\"Val  :\", class_distribution(val_ds))\n",
    "print(\"Test :\", class_distribution(test_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09473ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_distribution(ds, title: str) -> None:\n",
    "    dist = class_distribution(ds)\n",
    "    classes = list(dist.keys())\n",
    "    values = list(dist.values())\n",
    "\n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    plt.bar(classes, values)\n",
    "    plt.xlabel(\"Classe\")\n",
    "    plt.ylabel(\"Nombre d'images\")\n",
    "    plt.show()\n",
    "\n",
    "plot_distribution(train_ds, \"Distribution des classes — TRAIN\")\n",
    "plot_distribution(test_ds, \"Distribution des classes — TEST\")\n",
    "plot_distribution(val_ds, \"Distribution des classes — VAL\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b0eea89",
   "metadata": {},
   "source": [
    "## 4) Inspection visuelle\n",
    "\n",
    "Avant preprocessing, on affiche quelques exemples d’images pour chaque classe (NORMAL vs PNEUMONIA) afin d’observer :\n",
    "- la variabilité (contraste, luminosité),\n",
    "- le bruit,\n",
    "- la qualité générale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab604fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_images(paths: list[Path], title: str, n: int = 6) -> None:\n",
    "    n = min(n, len(paths))\n",
    "    chosen = random.sample(paths, n)\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.suptitle(title)\n",
    "\n",
    "    for i, p in enumerate(chosen, start=1):\n",
    "        img = Image.open(p)\n",
    "        plt.subplot(2, (n + 1) // 2, i)\n",
    "        plt.imshow(img, cmap=\"gray\")\n",
    "        plt.title(p.name[:20])\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da556a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_label = train_ds.class_to_idx[\"normal\"]\n",
    "pneumonia_label = train_ds.class_to_idx[\"pneumonia\"]\n",
    "\n",
    "train_normal_paths = [p for p, y in zip(train_ds.paths, train_ds.labels) if y == normal_label]\n",
    "train_pneumonia_paths = [p for p, y in zip(train_ds.paths, train_ds.labels) if y == pneumonia_label]\n",
    "\n",
    "len(train_normal_paths), len(train_pneumonia_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5589c243",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_images(train_normal_paths, \"Exemples TRAIN — NORMAL\", n=6)\n",
    "show_images(train_pneumonia_paths, \"Exemples TRAIN — PNEUMONIA\", n=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af077da9",
   "metadata": {},
   "source": [
    "## 5) Vérifications techniques\n",
    "\n",
    "On inspecte :\n",
    "- la taille des images (largeur/hauteur),\n",
    "- le mode (RGB ou grayscale),\n",
    "- les valeurs de pixels.\n",
    "\n",
    "Objectif : justifier le preprocessing (resize + normalisation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ef4bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inspect_sample(ds, n: int = 10) -> None:\n",
    "    n = min(n, len(ds.paths))\n",
    "    chosen = random.sample(ds.paths, n)\n",
    "\n",
    "    sizes = []\n",
    "    modes = []\n",
    "\n",
    "    for p in chosen:\n",
    "        img = Image.open(p)\n",
    "        sizes.append(img.size)   # (width, height)\n",
    "        modes.append(img.mode)   # 'RGB', 'L', ...\n",
    "\n",
    "    print(\"Exemples de tailles (width, height):\", sizes[:5])\n",
    "    print(\"Modes rencontrés:\", sorted(set(modes)))\n",
    "\n",
    "inspect_sample(train_ds, n=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617e8140",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inspect_pixel_range(ds, n: int = 10) -> None:\n",
    "    n = min(n, len(ds.paths))\n",
    "    chosen = random.sample(ds.paths, n)\n",
    "\n",
    "    mins, maxs = [], []\n",
    "    for p in chosen:\n",
    "        img = Image.open(p)\n",
    "        arr = np.array(img)\n",
    "        mins.append(arr.min())\n",
    "        maxs.append(arr.max())\n",
    "\n",
    "    print(\"Pixel min (échantillon):\", min(mins))\n",
    "    print(\"Pixel max (échantillon):\", max(maxs))\n",
    "\n",
    "inspect_pixel_range(train_ds, n=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b03dd3",
   "metadata": {},
   "source": [
    "## 6) Conclusions \n",
    "\n",
    "Observations principales :\n",
    "- Le dataset est réparti en splits train/val/test et en classes NORMAL/PNEUMONIA.\n",
    "- Le split **val** est très petit → on l’utilisera surtout pour valider le pipeline, et on pourra créer un split de validation depuis train si besoin.\n",
    "- Le dataset est **déséquilibré** (plus de PNEUMONIA que de NORMAL) → il faudra interpréter les métriques avec prudence (accuracy seule insuffisante).\n",
    "- Les images présentent une variabilité (taille, contraste) → preprocessing nécessaire :\n",
    "  - resize vers une taille fixe (ex: 224x224),\n",
    "  - normalisation des pixels (0..1),\n",
    "  - conversion de format cohérente (grayscale ou RGB selon choix).\n",
    "\n",
    "Prochaine étape (notebook 02) :\n",
    "- implémenter le preprocessing minimal,\n",
    "- entraîner un modèle baseline simple (ex: régression logistique) sur train,\n",
    "- évaluer sur test avec accuracy + precision/recall/F1 + matrice de confusion.      "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
